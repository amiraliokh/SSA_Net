{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading libraries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 10:44:24.563004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries successfuly!\n"
     ]
    }
   ],
   "source": [
    "from libraries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import DataGenerator, DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = DatasetManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 10:42:17.735598: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-23 10:42:17.737177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-23 10:42:17.794279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:17.794523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2023-04-23 10:42:17.794556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-23 10:42:17.827523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-23 10:42:17.827619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-23 10:42:17.846443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-23 10:42:17.850890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-23 10:42:17.883639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-23 10:42:17.888368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-23 10:42:17.943823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-23 10:42:17.943994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:17.944172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:17.944301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-04-23 10:42:17.945227: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-23 10:42:17.945869: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-23 10:42:17.945931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:17.946019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2023-04-23 10:42:17.946039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-23 10:42:17.946055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-23 10:42:17.946067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-23 10:42:17.946079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-23 10:42:17.946090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-23 10:42:17.946102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-23 10:42:17.946114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-23 10:42:17.946125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-23 10:42:17.946166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:17.946598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:17.946716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-04-23 10:42:17.947149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-23 10:42:19.010314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-23 10:42:19.010358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-04-23 10:42:19.010362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-04-23 10:42:19.011188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:19.011348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:19.011447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 10:42:19.011528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2805 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "loaded_data3 = manager.save_dataset_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_data3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 08:56:53.503432: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 207618048 exceeds 10% of free system memory.\n",
      "2023-04-22 08:56:53.615510: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 311427072 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "loaded_data2 = manager.save_dataset_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data2 = manager.load_dataset_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = DataGenerator(*loaded_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(datagen))\n",
    "len(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n",
      "(8, 512, 512, 2)\n"
     ]
    }
   ],
   "source": [
    "for x in datagen:\n",
    "    print(x[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show data generator output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=512x512>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image as im\n",
    "\n",
    "image = im.fromarray(datagen[1][0][1, :, :, 1].astype('uint8') * 255)\n",
    "image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = manager.split_data(loaded_data2, 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(train_data, val_data, test_data, n_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Physical devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m physical_devices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m config \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mexperimental\u001b[39m.\u001b[39;49mset_memory_growth(physical_devices[\u001b[39m0\u001b[39;49m], \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/config.py:594\u001b[0m, in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mconfig.experimental.set_memory_growth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    570\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_memory_growth\u001b[39m(device, enable):\n\u001b[1;32m    571\u001b[0m   \u001b[39m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \n\u001b[1;32m    573\u001b[0m \u001b[39m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[39m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m   context\u001b[39m.\u001b[39;49mcontext()\u001b[39m.\u001b[39;49mset_memory_growth(device, enable)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1448\u001b[0m, in \u001b[0;36mContext.set_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1448\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1449\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mPhysical devices cannot be modified after being initialized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_memory_growth_map[dev] \u001b[39m=\u001b[39m enable\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 10:44:50.427638: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-23 10:44:50.445942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-23 10:44:50.480852: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-23 10:44:50.480936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Amir-Ali-Notebook\n",
      "2023-04-23 10:44:50.480955: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Amir-Ali-Notebook\n",
      "2023-04-23 10:44:50.481222: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.105.17\n",
      "2023-04-23 10:44:50.481289: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.105.17\n",
      "2023-04-23 10:44:50.481305: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.105.17\n",
      "2023-04-23 10:44:50.482208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-23 10:44:50.484444: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "[ 0.53786856 10.02363965 24.36299235]\n",
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 10:44:52.588335: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 268435456 exceeds 10% of free system memory.\n",
      "2023-04-23 10:44:52.678481: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 536870912 exceeds 10% of free system memory.\n",
      "2023-04-23 10:44:53.010219: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 536870912 exceeds 10% of free system memory.\n",
      "2023-04-23 10:44:53.094803: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 536870912 exceeds 10% of free system memory.\n",
      "2023-04-23 10:44:53.153706: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 536870912 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 2.0686\n",
      "Seen so far: 1 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain_simple_loop(\u001b[39m10\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/media/amir_okh/New Volume1/Projects/SSA_Net Github/train.py:143\u001b[0m, in \u001b[0;36mTrainer.train_simple_loop\u001b[0;34m(self, epochs, batch_size, has_sc, has_sa)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m# Build model\u001b[39;00m\n\u001b[1;32m    141\u001b[0m model \u001b[39m=\u001b[39m SSA_Net(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes, has_sc, has_sa)\n\u001b[0;32m--> 143\u001b[0m episode_start_time, episode_losses, episode_train_metrics, episode_val_metrics, model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__training_loop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval_data, model, epochs, loss_fn, \u001b[39m'\u001b[39;49m\u001b[39msimple\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__optimizer(),  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__metrics(), batch_size, has_sa)\n\u001b[1;32m    145\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m---------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest training acc: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mamin(episode_train_metrics)\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/amir_okh/New Volume1/Projects/SSA_Net Github/train.py:89\u001b[0m, in \u001b[0;36mTrainer.__training_loop\u001b[0;34m(self, train_data, val_data, model, epochs, loss_fn, name, optimizer, metrics, batch_size, has_sa)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39m# Iterate over the batches of the dataset.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m step, (x_batch_train, y_batch_train) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_gen):\n\u001b[0;32m---> 89\u001b[0m     loss_value \u001b[39m=\u001b[39m train_step(x_batch_train, y_batch_train, weights)\n\u001b[1;32m     90\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss_value)\n\u001b[1;32m     91\u001b[0m     \u001b[39m# Log every 5 batches.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:824\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m RUN_FUNCTIONS_EAGERLY:\n\u001b[1;32m    823\u001b[0m   \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, tf_function_call\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meager\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 824\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n",
      "File \u001b[0;32m/media/amir_okh/New Volume1/Projects/SSA_Net Github/train.py:69\u001b[0m, in \u001b[0;36mTrainer.__training_loop.<locals>.train_step\u001b[0;34m(x, y, weights)\u001b[0m\n\u001b[1;32m     67\u001b[0m     logits \u001b[39m=\u001b[39m model(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m     loss_value \u001b[39m=\u001b[39m loss_fn(y, logits, weights, sa\u001b[39m=\u001b[39mhas_sa)\n\u001b[0;32m---> 69\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss_value, model\u001b[39m.\u001b[39;49mtrainable_weights)\n\u001b[1;32m     70\u001b[0m optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, model\u001b[39m.\u001b[39mtrainable_weights))\n\u001b[1;32m     71\u001b[0m train_acc_metric\u001b[39m.\u001b[39mupdate_state(y, logits[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:1080\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mif\u001b[39;00m output_gradients \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1078\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten(output_gradients)]\n\u001b[0;32m-> 1080\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   1082\u001b[0m     flat_targets,\n\u001b[1;32m   1083\u001b[0m     flat_sources,\n\u001b[1;32m   1084\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   1085\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   1086\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   1088\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   1089\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py:71\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 71\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     72\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     73\u001b[0m     target,\n\u001b[1;32m     74\u001b[0m     sources,\n\u001b[1;32m     75\u001b[0m     output_gradients,\n\u001b[1;32m     76\u001b[0m     sources_raw,\n\u001b[1;32m     77\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:162\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py:597\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    578\u001b[0m shape_0, shape_1 \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape_n([op\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m], op\u001b[39m.\u001b[39minputs[\u001b[39m1\u001b[39m]])\n\u001b[1;32m    580\u001b[0m \u001b[39m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[39m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[39m# `explicit_paddings` parameter, but nn_ops functions do not. So if were were\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[39m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[39m# in Eager mode.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    587\u001b[0m     gen_nn_ops\u001b[39m.\u001b[39mconv2d_backprop_input(\n\u001b[1;32m    588\u001b[0m         shape_0,\n\u001b[1;32m    589\u001b[0m         op\u001b[39m.\u001b[39minputs[\u001b[39m1\u001b[39m],\n\u001b[1;32m    590\u001b[0m         grad,\n\u001b[1;32m    591\u001b[0m         dilations\u001b[39m=\u001b[39mdilations,\n\u001b[1;32m    592\u001b[0m         strides\u001b[39m=\u001b[39mstrides,\n\u001b[1;32m    593\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m    594\u001b[0m         explicit_paddings\u001b[39m=\u001b[39mexplicit_paddings,\n\u001b[1;32m    595\u001b[0m         use_cudnn_on_gpu\u001b[39m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m    596\u001b[0m         data_format\u001b[39m=\u001b[39mdata_format),\n\u001b[0;32m--> 597\u001b[0m     gen_nn_ops\u001b[39m.\u001b[39;49mconv2d_backprop_filter(\n\u001b[1;32m    598\u001b[0m         op\u001b[39m.\u001b[39;49minputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    599\u001b[0m         shape_1,\n\u001b[1;32m    600\u001b[0m         grad,\n\u001b[1;32m    601\u001b[0m         dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[1;32m    602\u001b[0m         strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m    603\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m    604\u001b[0m         explicit_paddings\u001b[39m=\u001b[39;49mexplicit_paddings,\n\u001b[1;32m    605\u001b[0m         use_cudnn_on_gpu\u001b[39m=\u001b[39;49muse_cudnn_on_gpu,\n\u001b[1;32m    606\u001b[0m         data_format\u001b[39m=\u001b[39;49mdata_format)\n\u001b[1;32m    607\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py:1080\u001b[0m, in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   1079\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   1081\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mConv2DBackpropFilter\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, filter_sizes, out_backprop,\n\u001b[1;32m   1082\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mstrides\u001b[39;49m\u001b[39m\"\u001b[39;49m, strides, \u001b[39m\"\u001b[39;49m\u001b[39muse_cudnn_on_gpu\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_cudnn_on_gpu, \u001b[39m\"\u001b[39;49m\u001b[39mpadding\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1083\u001b[0m       padding, \u001b[39m\"\u001b[39;49m\u001b[39mexplicit_paddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, explicit_paddings, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1084\u001b[0m       data_format, \u001b[39m\"\u001b[39;49m\u001b[39mdilations\u001b[39;49m\u001b[39m\"\u001b[39;49m, dilations)\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   1086\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train_simple_loop(10, 1, False, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
